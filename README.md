# ğŸ“š Automated Book Publication Workflow

A robust AI-driven pipeline for web-based chapter extraction, AI "spinning", multi-phase human review, voice synthesis, semantic versioning, and RL-based reward evaluation.

---

## ğŸ¯ Objective

This project automates the book publishing workflow using AI and human-in-the-loop design. It fetches a chapter from a URL, uses a Large Language Model (LLM) to rewrite and review the text, enables human editing, evaluates with reinforcement learning techniques, and stores versions with semantic search.

---

## ğŸ› ï¸ Key Features

| Feature                          | Description                                                                 |
|----------------------------------|-----------------------------------------------------------------------------|
| âœ… Web Scraping & Screenshot     | Extracts chapter text and captures page image from Wikisource               |
| ğŸ¤– AI Writer & Reviewer          | Uses FLAN-T5 to "spin" and review chapter content                           |
| ğŸ‘¤ Human-in-the-Loop             | Allows human editing and rewards it using BLEU and readability scores       |
| ğŸ™ï¸ Voice Agent                  | Reads out final chapter via offline TTS (`pyttsx3`)                        |
| ğŸ§  ChromaDB Versioning           | Stores each version with semantic embedding for search and tracking        |
| ğŸ§ª RL-Based Reward System        | Computes reward for human edits using NLP metrics                           |
| ğŸ” Semantic Search               | Search historical versions for terms or phrases using vector similarity     |

---

## ğŸŒ Source URL

> Example Chapter:  
> [`https://en.wikisource.org/wiki/The_Gates_of_Morning/Book_1/Chapter_1`](https://en.wikisource.org/wiki/The_Gates_of_Morning/Book_1/Chapter_1)

---

## ğŸ“ Folder Structure
```
Automated-Book-Publication-Workflow/
â”œâ”€â”€ output/ # All intermediate and final text outputs
â”œâ”€â”€ chroma_storage/ # Vector DB files for ChromaDB
â”œâ”€â”€ pycache/ # Auto-generated Python bytecode (ignored)
â”œâ”€â”€ ai_writer_chunked.py # AI chapter spinner (FLAN-T5)
â”œâ”€â”€ human_editor.py # Human review + RL-based scoring
â”œâ”€â”€ ai_reviewer.py # [Optional] Separate AI reviewer logic
â”œâ”€â”€ chroma_manager.py # Handles ChromaDB versioning & search
â”œâ”€â”€ scrape_and_screenshot.py # Web scraping and screenshot capture
â”œâ”€â”€ voice_agent.py # Text-to-speech voice agent
â”œâ”€â”€ run_scraper.py # Script to run web scraping
â”œâ”€â”€ run_pipeline.py # Master pipeline runner
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # ğŸ“˜ You're here
```


---

## ğŸ”„ Pipeline Overview

```text
Step 1: Scrape chapter from web & screenshot it
Step 2: AI spins chapter (FLAN-T5)
Step 3: AI reviews it (refines further)
Step 4: Human edits are introduced
Step 5: BLEU and readability rewards are computed
Step 6: Final output is read aloud by TTS agent
Step 7: Version is saved to ChromaDB with metadata
Step 8: Semantic search enabled for previous revisions
```
---
## ğŸš€ Getting Started
1. Clone the Repo
- git clone https://github.com/githubabhay2003/Automated-Book-Publication-Workflow.git
- cd Automated-Book-Publication-Workflow

2. Install Dependencies
pip install -r requirements.txt

3. Run the Workflow
---
## Scrape chapter
python run_scraper.py

## Run AI-human pipeline
python run_pipeline.py

---
## ğŸ§  Tools & Technologies

| Tool           Â  Â  Â  Â  Â  Â  Â  Â  Â  | Purpose                                         Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
|---------------------------------|---------------------------------------------------------------------------------|
| `transformers`Â  Â  Â  Â  Â  Â  Â  Â  Â  | FLAN-T5 model for AI text generationÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| `torch`Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | Backend for running modelsÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| `nltk`Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | BLEU scoring for human edit qualityÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| `textstat`Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | Flesch Reading Ease scoringÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â |
| `pyttsx3`Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â | Offline voice agentÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â |
| `ChromaDB`Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | Vector DB for versioning/searchÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â |
| `duckdb`Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | Storage backend for ChromaDBÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
| `Playwright`Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  | Web scraping and screenshotsÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  |
---
## ğŸ“Š RL-Based Reward Metrics
Human edits are evaluated based on:

BLEU Score: How similar the edited text is to the AI's version

Flesch Reading Ease: Measures human readability

Delta Diff: Shows actual line-by-line edits

Reward results are saved to:
ğŸ“„ output/reward_log.txt

## ğŸ” Semantic Search Demo
Example query from the pipeline:
- ğŸ” Searching for: 'Karolin'
- Result: v1_final_ai - Chapter where term "Karolin" appears.
- Semantic matching is based on all-MiniLM-L6-v2 embedding model.

##ğŸ“¦ Requirements
```
transformers==4.41.1
torch>=2.0.0
nltk>=3.8.1
textstat>=0.7.3
chromadb>=0.5.0
pyttsx3>=2.90
pandas>=2.0.0
scikit-learn>=1.3.0
duckdb>=0.10.1
sentence-transformers>=2.2.2
```
## ğŸ“œ License
- MIT License â€” for evaluation purposes only.
- âš ï¸ This is a test assignment for Soft-Nerve, not a commercial product.

## ğŸ™‹ Author
- Abhay Kumar Saini
- GitHub: @githubabhay2003
